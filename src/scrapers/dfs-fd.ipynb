{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def format_date(date):\n",
    "    \"\"\"\n",
    "    Takes the date uniforms the format\n",
    "    :param date_str:\n",
    "        yyyymmdd(int)\n",
    "    :return:\n",
    "        list of ints: [yyyy,mm,dd]\n",
    "    \"\"\"\n",
    "    return [int(str(date)[x:y]) for x, y in zip([0, 4, 6], [4, 6, 8])]\n",
    "\n",
    "def get_date_range(range_list):\n",
    "    \"\"\"\n",
    "    Takes a list of [start date, end date] and makes a list of the range (inclusive)\n",
    "    :param range_list:\n",
    "        [yyyymmdd, yyyymmdd]\n",
    "    :return:\n",
    "        a list of datetime.date objects\n",
    "    \"\"\"\n",
    "    start_date = datetime.date(*format_date(range_list[0]))\n",
    "    end_date = datetime.date(*format_date(range_list[1]))\n",
    "\n",
    "    delta = end_date - start_date\n",
    "\n",
    "    return [end_date - datetime.timedelta(days=n) for n in range(delta.days+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(date):\n",
    "    \"\"\"\n",
    "    Returns formatted date\n",
    "    :param date:\n",
    "        datetime.date instance\n",
    "    \"\"\"\n",
    "    # convert date obj to strings and make sure single digit days have leading 0\n",
    "    day, month, year = str(date.day).zfill(2), str(date.month), str(date.year)\n",
    "\n",
    "    return 'mon={}&day={}&year={}'.format(month, day, year)\n",
    "\n",
    "def get_url(date, site): \n",
    "    \"\"\"\n",
    "    creates the url to scrape from.\n",
    "    :param date:\n",
    "        formatted date to scrape from\n",
    "        example: &mon=3&day=13&year=2016\n",
    "    :param site:\n",
    "        FantasyDuel or DraftKing\n",
    "        example: fd | dk\n",
    "    :return:\n",
    "        formatted URL\n",
    "    \"\"\"\n",
    "    return 'http://rotoguru1.com/cgi-bin/hyday.pl?game=' + site + '&' + get_date(date)\n",
    "\n",
    "\n",
    "def fetch_player_data(date, url, site):\n",
    "    \"\"\"\n",
    "    scrapes the player data from the given web page.\n",
    "    :param date:\n",
    "        current date to scrape\n",
    "    :param url:\n",
    "        url of the page \n",
    "        example: 'http://rotoguru1.com/cgi-bin/hyday.pl?game=fd&mon=3&day=13&year=2016'\n",
    "    :param site:\n",
    "        fd for FantasyDuel | dk for DraftKing\n",
    "    :return:\n",
    "        a list of player data\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    data = []\n",
    "    data.append([\"Position\", \"Name\", \"Fantasy Points\", \"Salary\", \"Away\", \"Home\", \"Score\", \"Minutes\", \"Stats\", \n",
    "                 \"Site\", \"ID\", \"Date\", \"First Name\", \"Last Name\"])\n",
    "    \n",
    "    for n, player_row in enumerate(soup.find_all('tr')):\n",
    "        pos = player_row.find('b')\n",
    "\n",
    "        # Differentiate player rows by number of td tags.\n",
    "        if len(player_row.findParents('table')) == 0 and\\\n",
    "                player_row.find('td', {'colspan':False}) and\\\n",
    "                len(player_row.find_all('b')) == 0:\n",
    "            player_id = urlparse(player_row.find('a')['href']).query\n",
    "            # Get the td tag text and format it.\n",
    "            player_data = [data.text.replace(u'\\xa0', u'').strip() for data in player_row.find_all('td')]\n",
    "            player_data.append(site)\n",
    "            player_data.append(player_id)\n",
    "            player_data.append(date)\n",
    "            player_data.append(player_data[1].split(\",\")[1].replace(\"^\", \"\"))\n",
    "            player_data.append(player_data[1].split(\",\")[0])\n",
    "            \n",
    "            data.append(player_data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(date_range):\n",
    "    date_list = get_date_range(date_range)\n",
    "    \n",
    "    for date in date_list:\n",
    "        print(date)\n",
    "        \n",
    "        url = get_url(date, 'fd')\n",
    "        \n",
    "        print(url)\n",
    "\n",
    "        scraped_data = fetch_player_data(str(date), url, 'fd')\n",
    "        \n",
    "        print(scraped_data)\n",
    "        \n",
    "        print(len(scraped_data), \"rows of player data scraped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#main([20151027, 20151028])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
